{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "WosjT1B5VeBj",
      "metadata": {
        "id": "WosjT1B5VeBj"
      },
      "source": [
        "# 1. ANN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HtX76CHOYLCs",
      "metadata": {
        "id": "HtX76CHOYLCs"
      },
      "source": [
        "## Backpropagation의 가중치 업데이트\n",
        "\n",
        "다음은 17페이지에 제시된 **역전파(Backpropagation) 과정 중 가중치 업데이트 단계**를 나타낸 식이다.\n",
        "\n",
        "가중치 업데이트 단계는 앞선 단계에서 계산된 오차의 기울기를 이용해  \n",
        "손실 함수(Error)를 최소화하는 방향으로 가중치를 조정하는 과정이며,  \n",
        "이때 사용되는 규칙은 대표적인 **최적화 기법**에 해당한다.  \n",
        "\n",
        "\n",
        "$$\n",
        "W^{(l)} \\leftarrow W^{(l)} - \\alpha \\frac{\\partial E}{\\partial W^{(l)}}\n",
        "$$\n",
        "\n",
        "\n",
        "##  문제\n",
        "\n",
        "1. 위 가중치 업데이트 식이 의미하는 **최적화 기법**이 무엇인지 설명하시오.  \n",
        "2. 위 식에서  \n",
        "$$\n",
        "\\frac{\\partial E}{\\partial W^{(l)}}\n",
        "$$\n",
        "   가 어떻게 계산되는지를 **Chain Rule(연쇄법칙)** 을 이용해 설명하시오.  \n",
        "\n",
        "   (Hint: 세션 자료 하단에 제시된 최종 결과식을 참고헤 도출 과정 서술하면 됨)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K7U-jSljepw-",
      "metadata": {
        "id": "K7U-jSljepw-"
      },
      "source": [
        "### 답변 1 :\n",
        "\n",
        "위 가중치 업데이트 식이 의미하는 최적화 기법은 **경사 하강법(Gradient Descent)** 이다.\n",
        "\n",
        "경사 하강법은 손실 함수 $E$를 최소화하기 위해, 가중치 $W^{(l)}$을 손실 함수의 기울기(gradient)인 $\\frac{\\partial E}{\\partial W^{(l)}}$의 반대 방향으로 조금씩 이동시키는 최적화 방법이다.\n",
        "\n",
        "식에서 $\\alpha$는 학습률(learning rate)로, 한 번의 업데이트에서 가중치를 얼마나 크게 조정할지 결정한다. 즉, 현재 가중치에서 오차가 증가하는 방향의 반대 방향으로 가중치를 갱신함으로써, 반복적으로 손실 함수를 감소시키는 방식이다.  \n",
        "<br>\n",
        "\n",
        "### 답변 2 :\n",
        "\n",
        "$\\frac{\\partial E}{\\partial W^{(l)}}$는 **연쇄법칙(Chain Rule)** 을 이용하여 계산된다.\n",
        "\n",
        "가중치 $W^{(l)}$는 바로 오차 $E$에 영향을 주지 않고 가중합 $z^{(l)}$, 활성화 함수 출력 $a^{(l)}$을 거쳐 간접적으로 영향을 미친다.\n",
        "\n",
        "따라서 다음과 같이 미분을 분해할 수 있다.\n",
        "\n",
        "$$\\frac{\\partial E}{\\partial W^{(l)}} = \\frac{\\partial E}{\\partial a^{(l)}} \\cdot \\frac{\\partial a^{(l)}}{\\partial z^{(l)}} \\cdot \\frac{\\partial z^{(l)}}{\\partial W^{(l)}}$$\n",
        "\n",
        "여기서\n",
        "\n",
        "- $\\frac{\\partial E}{\\partial a^{(l)}}$는 출력 오차가 현재 층의 활성값에 미치는 영향\n",
        "- $\\frac{\\partial a^{(l)}}{\\partial z^{(l)}}$는 활성화 함수의 미분\n",
        "- $\\frac{\\partial z^{(l)}}{\\partial W^{(l)}}$는 가중치에 대한 선형 결합의 미분이다\n",
        "\n",
        "이러한 연쇄적인 미분 계산을 통해 각 층의 가중치에 대한 오차 기울기를 구하고, 이를 이용해 역전파(backpropagation) 과정에서 가중치를 업데이트한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fksAbmqRnd7M",
      "metadata": {
        "id": "fksAbmqRnd7M"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GIgRo97NVut1",
      "metadata": {
        "id": "GIgRo97NVut1"
      },
      "source": [
        "# 2. DNN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ny9dzza0f3kS",
      "metadata": {
        "id": "Ny9dzza0f3kS"
      },
      "source": [
        "다음은 세션 자료 25p의 과제의 내용이다. 자료에 주어진 조건을 바탕으로 아래 문제들을 해결하시오.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. 파라미터 수 직접 계산하기**\n",
        "주어진 신경망 구조(784 - 16 - 16 - 10)를 기준으로 총 학습 파라미터 수(가중치 $W$ 및 편향 $b$)를 직접 계산하시오.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ckt1B2wzgdlI",
      "metadata": {
        "id": "ckt1B2wzgdlI"
      },
      "source": [
        "### 답변 :\n",
        " **1층 (784 → 16)**\n",
        "\n",
        "- 가중치 $W$: $784 \\times 16 = 12544$\n",
        "- 편향 $b$: $16$\n",
        "\n",
        "합: $12544 + 16 = 12560$\n",
        "\n",
        "\n",
        "**2층 (16 → 16)**\n",
        "\n",
        "- 가중치 $W$: $16 \\times 16 = 256$\n",
        "- 편향 $b$: $16$\n",
        "\n",
        "합: $256 + 16 = 272$\n",
        "\n",
        "\n",
        "\n",
        "**3층 (16 → 10)**\n",
        "\n",
        "- 가중치 $W$: $16 \\times 10 = 160$\n",
        "- 편향 $b$: $10$\n",
        "\n",
        "합: $160 + 10 = 170$\n",
        "\n",
        "\n",
        "\n",
        "$$12560 + 272 + 170 = 13002$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZAPWAdGFg81y",
      "metadata": {
        "id": "ZAPWAdGFg81y"
      },
      "source": [
        "---\n",
        "\n",
        "### **2. TensorFlow 모델 구현 및 검증**\n",
        "동일한 구조의 DNN을 TensorFlow/Keras 코드로 구현하고, `model.summary()` 출력 결과와 위에서 계산한 값이 일치하는지 확인하시오. (학습 과정은 필요 X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "RgagRLxIk6r1",
      "metadata": {
        "id": "RgagRLxIk6r1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7eca375d-c534-4798-cbf9-b54759aa07d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m12,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m170\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,002\u001b[0m (50.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,002</span> (50.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,002\u001b[0m (50.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,002</span> (50.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "## 1. 적절한 라이브러리를 import하세요\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "\n",
        "## 2. 모델 설계하기\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "## 3. 모델 summary 출력\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wofnlYRFl0jH",
      "metadata": {
        "id": "wofnlYRFl0jH"
      },
      "source": [
        "---\n",
        "\n",
        "### **3. 결과 비교**\n",
        "1번에서 직접 계산한 학습 파라미터 수와 model.summary() 출력 결과의 Total params 값이\n",
        "서로 일치하는지 확인하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PJ-HtPs5mqwu",
      "metadata": {
        "id": "PJ-HtPs5mqwu"
      },
      "source": [
        "### 답변 :\n",
        "1번에서 직접 계산한 총 학습 파라미터 수는 13002개이며,\n",
        "model.summary()의 Total params 값 또한 13002로 **동일하다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lnI4oyzXVu6h",
      "metadata": {
        "id": "lnI4oyzXVu6h"
      },
      "source": [
        "# 3. CNN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96843df4",
      "metadata": {
        "id": "96843df4"
      },
      "source": [
        "---\n",
        "## **Introduction**\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:3744/format:webp/1*SGPGG7oeSvVlV5sOSQ2iZw.png)\n",
        "([Image Credit](https://medium.com/data-science/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9))\n",
        "\n",
        "Pytorch를 사용하여 이미지와 같이 MNIST 데이터셋을 분류하는 CNN 모델을 구현해봅시다.   \n",
        "Pytorch가 익숙하지 않은 분들은 [다음 튜토리얼](https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)을 참고해주세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2b0f60",
      "metadata": {
        "id": "8c2b0f60"
      },
      "source": [
        "---\n",
        "## **1. Import Libraries & Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a8e21858",
      "metadata": {
        "id": "a8e21858"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리를 불러옵니다.\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f26c1020",
      "metadata": {
        "id": "f26c1020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8a0d59-0042-4e7f-d845-165af96f0144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 48.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.65MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.3MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.08MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 이미지 변환 함수를 정의합니다.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) ## 1. 이미지에 Normalize를 하는 이유와 2. 다음과 같은 숫자를 사용한 이유는 무엇일까요? (답은 작성하지 않으셔도 됩니다.)\n",
        "])\n",
        "\n",
        "# 데이터셋을 불러오고, DataLoader를 사용하여 데이터를 로드합니다.\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bfebc3c1",
      "metadata": {
        "id": "bfebc3c1",
        "outputId": "e7ca997e-efa0-4382-fca5-184eb6b293bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set size: 60000\n",
            "test set size: 10000\n",
            "\n",
            "training set dimension: torch.Size([60000, 28, 28])\n",
            "test set dimension: torch.Size([10000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "## 데이터셋의 크기와 차원을 확인합니다.\n",
        "print(f'training set size: {len(trainset)}')\n",
        "print(f'test set size: {len(testset)}\\n')\n",
        "\n",
        "print(f'training set dimension: {trainset.data.shape}')\n",
        "print(f'test set dimension: {testset.data.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a787a4e2",
      "metadata": {
        "id": "a787a4e2"
      },
      "source": [
        "---\n",
        "## **2. Define a Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8ebc72e",
      "metadata": {
        "id": "a8ebc72e"
      },
      "source": [
        "주어진 모델을 다시 한 번 정리해봅시다.\n",
        "\n",
        "\n",
        "**Conv_1** : 3x3 filter 32개, stride: 1, padding: 1, activation = 'relu'   \n",
        "**Pool_2** : 2x2 filter, stride: 2, padding: 0  \n",
        "**Conv_3** : 3x3 filter 64개, stride: 1, padding: 1, activation = 'relu'   \n",
        "**Pool_4** : 2x2 filter, stride: 2, padding: 0   \n",
        "**Dense_5** : 128, activation = 'relu'   \n",
        "**Dense_6** : 10, activation = 'softmax'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1961c671",
      "metadata": {
        "id": "1961c671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f666e6-3c4b-4c95-ec7d-03f8cb579f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dense5): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (dense6): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 아래 코드의 빈칸을 채워주세요!\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.dense5 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dense6 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool4(x)\n",
        "        x = torch.flatten(x, 1) # flatten layer: 2D -> 1D\n",
        "        x = F.relu(self.dense5(x))\n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "\n",
        "cnn = CNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0735fb3a",
      "metadata": {
        "id": "0735fb3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8f98c8-4619-470c-d500-bc1cb569c1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dense5): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (dense6): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.dense5 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dense6 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool4(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.dense5(x))\n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "\n",
        "cnn = CNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2546f642",
      "metadata": {
        "id": "2546f642"
      },
      "source": [
        "#### **문제: 주어진 모델에 대해, layer마다 필요한 parameter의 수를 계산하세요.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e2dd6b",
      "metadata": {
        "id": "b2e2dd6b"
      },
      "source": [
        "- Conv_1: 320\n",
        "- Pool_2: 0\n",
        "- Conv_3: 18496\n",
        "- Pool_4: 0\n",
        "- FC_5: 401536\n",
        "- FC_6: 1290"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cf8b00a9",
      "metadata": {
        "id": "cf8b00a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4af6ea-6189-48e3-ae1e-2e0e101a4e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
            "            Conv2d-3           [-1, 64, 14, 14]          18,496\n",
            "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
            "            Linear-5                  [-1, 128]         401,536\n",
            "            Linear-6                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 421,642\n",
            "Trainable params: 421,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.36\n",
            "Params size (MB): 1.61\n",
            "Estimated Total Size (MB): 1.97\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# summary를 사용하여 정답과 계산 결과가 일치하는지 확인하세요.\n",
        "# !pip install torchsummary\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(cnn, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc55961",
      "metadata": {
        "id": "fbc55961"
      },
      "source": [
        "---\n",
        "## **3. Train a model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d9fce42e",
      "metadata": {
        "id": "d9fce42e"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "969c0825",
      "metadata": {
        "id": "969c0825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fa8a0f-dd0f-4b6b-b8fe-bf000892b3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1, 100] loss: 0.547\n",
            "[Epoch: 1, 200] loss: 0.163\n",
            "[Epoch: 1, 300] loss: 0.099\n",
            "[Epoch: 1, 400] loss: 0.096\n",
            "[Epoch: 1, 500] loss: 0.080\n",
            "[Epoch: 1, 600] loss: 0.068\n",
            "[Epoch: 1, 700] loss: 0.060\n",
            "[Epoch: 1, 800] loss: 0.072\n",
            "[Epoch: 1, 900] loss: 0.056\n",
            "====== Epoch 1 Finished, Accuracy: 98.60% ======\n",
            "[Epoch: 2, 100] loss: 0.034\n",
            "[Epoch: 2, 200] loss: 0.044\n",
            "[Epoch: 2, 300] loss: 0.046\n",
            "[Epoch: 2, 400] loss: 0.048\n",
            "[Epoch: 2, 500] loss: 0.047\n",
            "[Epoch: 2, 600] loss: 0.046\n",
            "[Epoch: 2, 700] loss: 0.033\n",
            "[Epoch: 2, 800] loss: 0.035\n",
            "[Epoch: 2, 900] loss: 0.044\n",
            "====== Epoch 2 Finished, Accuracy: 98.95% ======\n",
            "[Epoch: 3, 100] loss: 0.022\n",
            "[Epoch: 3, 200] loss: 0.025\n",
            "[Epoch: 3, 300] loss: 0.027\n",
            "[Epoch: 3, 400] loss: 0.030\n",
            "[Epoch: 3, 500] loss: 0.029\n",
            "[Epoch: 3, 600] loss: 0.031\n",
            "[Epoch: 3, 700] loss: 0.035\n",
            "[Epoch: 3, 800] loss: 0.027\n",
            "[Epoch: 3, 900] loss: 0.029\n",
            "====== Epoch 3 Finished, Accuracy: 99.00% ======\n",
            "\n",
            "Training finished. Final accuracy: 99.00%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "    running_loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    # training loop\n",
        "    cnn.train()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # parameter gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = cnn(inputs) # 모델을 통해 output 계산\n",
        "        loss = criterion(outputs, labels) # loss 계산\n",
        "        loss.backward() # gradient 계산 (backpropagation)\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[Epoch: {epoch + 1}, {i + 1:3d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0\n",
        "\n",
        "    # testing loop\n",
        "    cnn.eval()\n",
        "    for i, data in enumerate(testloader):\n",
        "        inputs, labels = data\n",
        "        outputs = cnn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc += (predicted == labels).sum().item()\n",
        "    acc = acc / len(testloader.dataset)\n",
        "    print(f\"====== Epoch {epoch + 1} Finished, Accuracy: {acc*100:.2f}% ======\")\n",
        "\n",
        "print(f\"\\nTraining finished. Final accuracy: {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e92884",
      "metadata": {
        "id": "50e92884"
      },
      "source": [
        "---\n",
        "## **4. Experiment with the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a69031ab",
      "metadata": {
        "id": "a69031ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34ee04d-08b3-4c02-a899-f450f8df2be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "newCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dense5): Linear(in_features=6272, out_features=128, bias=True)\n",
            "  (dense6): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 기존의 모델을 원하는 대로 수정해보세요!\n",
        "# ex) layer 추가, kernel size 변경, optimizer 변경, activation 함수 변경, Dropout, etc.\n",
        "class newCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(newCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.dense5 = nn.Linear(128 * 7 * 7, 128)\n",
        "        self.dense6 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool4(x)\n",
        "        x = torch.flatten(x, 1) # flatten layer: 2D -> 1D\n",
        "        x = F.relu(self.dense5(x))\n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "\n",
        "new_cnn = newCNN()\n",
        "print(new_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e7b063f3",
      "metadata": {
        "id": "e7b063f3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(new_cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e3c143f9",
      "metadata": {
        "id": "e3c143f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f302860-e8d6-49e7-d798-4afc9bf1e334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1, 100] loss: 0.500\n",
            "[Epoch: 1, 200] loss: 0.144\n",
            "[Epoch: 1, 300] loss: 0.091\n",
            "[Epoch: 1, 400] loss: 0.068\n",
            "[Epoch: 1, 500] loss: 0.068\n",
            "[Epoch: 1, 600] loss: 0.060\n",
            "[Epoch: 1, 700] loss: 0.054\n",
            "[Epoch: 1, 800] loss: 0.057\n",
            "[Epoch: 1, 900] loss: 0.053\n",
            "====== Epoch 1 Finished, Accuracy: 98.93% ======\n",
            "[Epoch: 2, 100] loss: 0.039\n",
            "[Epoch: 2, 200] loss: 0.038\n",
            "[Epoch: 2, 300] loss: 0.038\n",
            "[Epoch: 2, 400] loss: 0.042\n",
            "[Epoch: 2, 500] loss: 0.032\n",
            "[Epoch: 2, 600] loss: 0.043\n",
            "[Epoch: 2, 700] loss: 0.034\n",
            "[Epoch: 2, 800] loss: 0.043\n",
            "[Epoch: 2, 900] loss: 0.043\n",
            "====== Epoch 2 Finished, Accuracy: 99.04% ======\n",
            "[Epoch: 3, 100] loss: 0.030\n",
            "[Epoch: 3, 200] loss: 0.024\n",
            "[Epoch: 3, 300] loss: 0.022\n",
            "[Epoch: 3, 400] loss: 0.020\n",
            "[Epoch: 3, 500] loss: 0.027\n",
            "[Epoch: 3, 600] loss: 0.028\n",
            "[Epoch: 3, 700] loss: 0.026\n",
            "[Epoch: 3, 800] loss: 0.025\n",
            "[Epoch: 3, 900] loss: 0.035\n",
            "====== Epoch 3 Finished, Accuracy: 99.09% ======\n",
            "\n",
            "Training finished. Final accuracy: 99.09%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "    running_loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    # training loop\n",
        "    new_cnn.train()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # parameter gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = new_cnn(inputs) # 모델을 통해 output 계산\n",
        "        loss = criterion(outputs, labels) # loss 계산\n",
        "        loss.backward() # gradient 계산 (backpropagation)\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[Epoch: {epoch + 1}, {i + 1:3d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0\n",
        "\n",
        "    # testing loop\n",
        "    new_cnn.eval()\n",
        "    for i, data in enumerate(testloader):\n",
        "        inputs, labels = data\n",
        "        outputs = new_cnn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc += (predicted == labels).sum().item()\n",
        "    acc = acc / len(testloader.dataset)\n",
        "    print(f\"====== Epoch {epoch + 1} Finished, Accuracy: {acc*100:.2f}% ======\")\n",
        "\n",
        "print(f\"\\nTraining finished. Final accuracy: {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b866aeb6",
      "metadata": {
        "id": "b866aeb6"
      },
      "source": [
        "### **기존의 모델에서 어떤 부분을 수정하였는지 설명해주세요.**\n",
        "\n",
        "답변 :\n",
        "기존 CNN 모델에서 두 번째 합성곱 층의 출력 채널 수를 64에서 128로 증가시켰다. 이에 따라 합성곱 층을 통해 추출되는 특징의 수가 늘어나므로, fully connected 층(dense5)의 입력 차원도 이에 맞게 수정하였다. 전체적인 네트워크 구조는 유지하면서 모델의 표현력을 확장하는 방향으로 변경하였다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d3904f",
      "metadata": {
        "id": "75d3904f"
      },
      "source": [
        "### **이러한 변경 사항이 결과에 어떻게 영향을 미쳤나요?**\n",
        "\n",
        "답변 :\n",
        "합성곱 층의 채널 수를 증가시킴으로써 입력 이미지로부터 더 다양한 특징을 학습할 수 있었고, 그 결과 기존 모델과 비교하여 분류 성능이 향상된 것을 확인하였다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeeea8a0",
      "metadata": {
        "id": "eeeea8a0"
      },
      "source": [
        "---\n",
        "## **5. (정말 마지막) 이론 문제**\n",
        "convolution이 무엇인지, 그리고 이를 이용하면 이미지의 feature를 추출할 수 있음을 이해하기 위한 문제입니다.\n",
        "\n",
        "다음과 같은 input과 kernel이 존재할 때, 발표 자료의 방식과 같이 feature map을 구하고, 그 결과를 ?에 적으시오.\n",
        "![](https://i.imgur.com/v1wkvhW.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73830a73",
      "metadata": {
        "id": "73830a73"
      },
      "source": [
        "정답:   \n",
        "1 0   \n",
        "0 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}